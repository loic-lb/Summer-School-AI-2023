{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://stergioc.github.io/assets/img/logos.png)\n",
    "\n",
    "# Summer School AI 2023\n",
    "\n",
    "## Introduction to computer vision & medical imaging\n",
    "\n",
    "In this lab, we will explore some basic image processing techniques using python and opencv. We will also explore some classic machine learning algorithms for image classification. The lab is divided into two parts. In the first part we will explore image processing techniques based on filtering and morphological operations and in the second part we will train a linear SVM classifier using some handcrafted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the data required for this lab, you can run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/scl/fi/euim7k5llvhcr76lf03y8/data.zip?rlkey=a7y6a91q8jgmh4kn98w95xf7d&dl=0\n",
    "!mv data.zip?rlkey=a7y6a91q8jgmh4kn98w95xf7d data.zip\n",
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7N63PG5iThzG"
   },
   "source": [
    "## Image Processing\n",
    "### 1) The dataset\n",
    "\n",
    "We will study the DRIVE dataset. The DRIVE database is composed of 40 retinal images, with the corresponding segmentation of blood vessels. Several features extracted from these vessels (length, width, branching patterns, ...) are used for the diagnosis, screening and treatment of various cardiovascular and ophthalmologic diseases. An automatic system for the segmentation of the retinal vasculature could therefore assist for the diagnosis of these diseases and the design of better treatment solutions.\n",
    "\n",
    "Each retinal image is of size 565x584 pixels. The images are in tif format and the ground truth is in gif format. The ground truth images are in the range [0,255], with the background at 0 and the vessels at 255. The retinal images are RGB in the range [0,255]. The training retinal images are in the folder training/images and the ground truth in the folder raining/1st_manual. The images are named as XX_training.tif and the ground truth as XX_manual1.gif where XX is the number of the image. For example the image 21 is named 21_training.tif and the ground truth 21_manual1.gif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the retinal images from the training set together with its ground truth, we will use the opencv (cv2) library. The cv2 library is a very popular library for image processing and computer vision. It is a python wrapper of the C++ library OpenCV. To read an image using cv2, we use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "hAaG3Yll1W-x",
    "outputId": "6e722475-5713-40cb-86c3-7433f75b9446"
   },
   "outputs": [],
   "source": [
    "ifolder = './DRIVE/training/images'\n",
    "gfolder = './DRIVE/training/1st_manual'\n",
    "\n",
    "\n",
    "def iread(fname, channels=1):\n",
    "    # we are working on rgb so flip the last axis of cv2 images as they are imported in bgr format by cv2\n",
    "    if channels == 1:\n",
    "        return cv2.imread(os.path.join(ifolder,fname))[:,:,1]\n",
    "    elif channels == 3:\n",
    "        return cv2.imread(os.path.join(ifolder,fname))[:,:,::-1]\n",
    "    else:\n",
    "        raise ValueError('channels must be 1 or 3')\n",
    "\n",
    "def gread(fname, channels=1):\n",
    "    if channels == 1:\n",
    "        return np.array(Image.open(os.path.join(gfolder, fname)).convert('L'))\n",
    "    elif channels == 3:\n",
    "        return np.array(Image.open(os.path.join(gfolder, fname)).convert('RGB'))\n",
    "    else:\n",
    "        raise ValueError('channels must be 1 or 3')\n",
    "\n",
    "im = iread('21_training.tif',1)\n",
    "gim = gread('21_manual1.gif')\n",
    "print(f'Retinal image shape: {im.shape}')\n",
    "print(f'Ground truth shape: {gim.shape}')\n",
    "fig = plt.figure(figsize=(23,16))\n",
    "plt.subplot(121),plt.imshow(im)\n",
    "plt.subplot(122),plt.imshow(gim, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Statistics\n",
    "\n",
    "We will now calculate a few statistics from the image. You will compute in particular the min, max, mean, std for the retinal image and the ground truth that you read before and print the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v2EJYMYk2ceH"
   },
   "outputs": [],
   "source": [
    "#calculate statistics of the image in particular calculate the min, max, mean, std for the im, gim that you read before and print the histogram\n",
    "\n",
    "########################ADD YOUR CODE HERE########################################\n",
    "\n",
    "\n",
    "\n",
    "##################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "What do you observe on the histogram ? What is the difference between the retinal image and the ground truth ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRp7LPMT8mLL"
   },
   "source": [
    "## 3) Histogram processing\n",
    "\n",
    "You will now implement some histogram equalization techniques. In particular, you will implement histogram equalization and CLAHE. You will apply them on the retinal image and print the results. You may take a look [here](https://docs.opencv.org/4.x/d5/daf/tutorial_py_histogram_equalization.html) for some hints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NM5DO0wW3eoo"
   },
   "outputs": [],
   "source": [
    "#HISTOGRAM PROCESSING\n",
    "########################ADD YOUR CODE HERE########################################\n",
    "#Histogram Equalization\n",
    "\n",
    "\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HISTOGRAM PROCESSING\n",
    "########################ADD YOUR CODE HERE########################################\n",
    "#Histogram Contrast Limited Adaptive Histogram Equalization (CLAHE)\n",
    "\n",
    "\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "What do you observe on the histogram and the processed image ? What is the difference between the two methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Filtering\n",
    "\n",
    "You will now implement some filtering techniques for denoising. In particular, you will implement Gaussian filtering and Non Local Mean Denoising to smooth the retinal image and print the result. You may take a look [here](https://docs.opencv.org/4.x/d4/d13/tutorial_py_filtering.html) and [here](https://docs.opencv.org/3.4/d5/d69/tutorial_py_non_local_means.html) for some hints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R635kRPb5BUV"
   },
   "outputs": [],
   "source": [
    "#FILTERING, LOW PASS FILTERS/ SMOOTHING\n",
    "########################ADD YOUR CODE HERE########################################\n",
    "#Apply a Gaussian filter for smoothing the image\n",
    "\n",
    "\n",
    "#Apply a Non Local Mean Denoising filter for smoothing the image\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "#print the filtered images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "What do you observe on the filtered image ? Try to play with the parameters of the filters to understand their effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now move on to edge detection. You will first apply a Canny filter on both the original and filtered image, and then repeat the same with a Sobel filter. You may take a look [here](https://docs.opencv.org/3.4/da/d22/tutorial_py_canny.html) and [here](https://docs.opencv.org/4.x/d2/d2c/tutorial_sobel_derivatives.html) for some hints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "32gssc2r6UZ1"
   },
   "outputs": [],
   "source": [
    "#FILTERING, HIGH PASS FILTERS/ EDGE DETECTION\n",
    "########################ADD YOUR CODE HERE########################################\n",
    "#Apply a Canny filter for edge detection. Apply it on the original and dst images.\n",
    "\n",
    "\n",
    "\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILTERING, HIGH PASS FILTERS/ EDGE DETECTION\n",
    "########################ADD YOUR CODE HERE########################################\n",
    "#Apply a Sobel filter on the original image and print the result.\n",
    "\n",
    "\n",
    "\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "What difference do you observe between the original and filtered image ? Between the two methods ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Morphological operations\n",
    "\n",
    "You will now apply morphological closing for edge extraction. Apply it on the edge detection constructed with the Canny filter on both the original and filtered image. You may take a look [here](https://docs.opencv.org/3.4/d9/d61/tutorial_py_morphological_ops.html) for some hints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzOYUOUa72Xx"
   },
   "outputs": [],
   "source": [
    "#MORPHOLOGICAL FILTERING\n",
    "########################ADD YOUR CODE HERE########################################\n",
    "#Apply morphological closing for edge extraction. Apply it on the original and dst images.\n",
    "\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Try to play with the parameters to understand their effect. What do you observe now ? Between the results produced by the original and the filtered image ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional, apply the opening operation. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################ADD YOUR CODE HERE########################################\n",
    "#Optional, apply the opening operation.\n",
    "\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now evaluate the performance of this method vessels segmentation. You may use sklearn to print the confusion matrix for both closing and closing_gdst results comparing it with the ground truth. You may take a look [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) for some hints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dq8ox8WZ92WZ"
   },
   "outputs": [],
   "source": [
    "#EVALUATION OF THE MORPHOLOGICAL OPERATIONS FOR EDGE DETECTION\n",
    "from sklearn.metrics import confusion_matrix\n",
    "########################ADD YOUR CODE HERE########################################\n",
    "#Using sklearn print the confusion matrix\n",
    "\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional, calculate yourself without sklearn the precision and recall of the pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################ADD YOUR CODE HERE########################################\n",
    "#Optional, calculate yourself without sklearn the precision and recall of the pair\n",
    "\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "## 1) Supervised classification\n",
    "\n",
    "We will now train a linear SVM model using different handcrafted features such as the image intensities, edges and morphological operations. You may take a look [here](https://scikit-learn.org/stable/modules/svm.html) for more details on SVM sklearn implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wuq29Pql___F"
   },
   "outputs": [],
   "source": [
    "################SUPERVISED CLASSIFICATION##########################################\n",
    "from sklearn import svm\n",
    "\n",
    "###########ADD YOUR CODE HERE ############################################\n",
    "# Define your features for example you can take the intensities, the denoising, the Canny and the Morphological Features\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "\n",
    "#We will train and evaluate the model using only the im image, using 100 samples.\n",
    "nsamples = 100\n",
    "rng = np.random.default_rng(1)\n",
    "\n",
    "#####################ADD YOUR CODE HERE##############################################\n",
    "#Fit and SVM algorithm and use it to predict the labels.\n",
    "\n",
    "########################################################################################\n",
    "#Print the result\n",
    "#fig = plt.figure(figsize=(23,16))\n",
    "#plt.subplot(121),plt.imshow(gim)\n",
    "#plt.subplot(122),plt.imshow(result,cmap='gray')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the model using a confusion matrix. Compare the results with the ones obtained with the morphological operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################ADD YOUR CODE HERE########################################\n",
    "\n",
    "\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now generalize the previous code to read all the training images and pick 100 positives and 100 negative pixels to generate a training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m1iLEmmDB3XK"
   },
   "outputs": [],
   "source": [
    "########################ADD YOUR CODE HERE########################################\n",
    "\n",
    "\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate your performance using the image 21 as before. What do you observe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################ADD YOUR CODE HERE########################################\n",
    "\n",
    "\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional, visualize the results on some test images. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################ADD YOUR CODE HERE########################################\n",
    "\n",
    "\n",
    "#################################################################################"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
